# ç›‘æ§ä¸å‘Šè­¦æ–¹æ¡ˆ

## æ–‡æ¡£ä¿¡æ¯

- **ç‰ˆæœ¬**: v1.0
- **æœ€åæ›´æ–°**: 2026-02-13
- **è´Ÿè´£äºº**: è¿ç»´å›¢é˜Ÿ
- **é€‚ç”¨èŒƒå›´**: v0.1 MVP ç‰ˆæœ¬

## ä¸€ã€ç›‘æ§æ¦‚è¿°

### 1.1 ç›‘æ§ç›®æ ‡

- **ç³»ç»Ÿå¯ç”¨æ€§**: ç¡®ä¿æœåŠ¡ 7Ã—24 å°æ—¶ç¨³å®šè¿è¡Œ
- **æ€§èƒ½ç›‘æ§**: å®æ—¶è·Ÿè¸ªç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
- **å¼‚å¸¸æ£€æµ‹**: åŠæ—¶å‘ç°å¹¶å“åº”å¼‚å¸¸æƒ…å†µ
- **å®¹é‡è§„åˆ’**: ä¸ºæ‰©å®¹æä¾›æ•°æ®æ”¯æŒ

### 1.2 æŠ€æœ¯é€‰å‹

- **æŒ‡æ ‡é‡‡é›†**: Prometheus
- **å¯è§†åŒ–**: Grafana
- **å‘Šè­¦**: Alertmanager + Slack/é‚®ä»¶
- **æ—¥å¿—**: Loki + Promtail
- **APM**: (å¯é€‰) Sentry / Jaeger

## äºŒã€ç›‘æ§æ¶æ„

### 2.1 æ•´ä½“æ¶æ„

\`\`\`
åº”ç”¨å±‚                    é‡‡é›†å±‚             å­˜å‚¨å±‚          å±•ç¤ºå±‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API    â”‚â”€â”€â”€metricsâ”€â†’â”‚Prometheusâ”‚â”€â”€â”€â”€â”€â†’â”‚ TSDB    â”‚â”€â”€â”€â”€â†’â”‚ Grafana â”‚
â”‚ Service â”‚           â”‚ Exporter â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
                                                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  Web    â”‚â”€â”€â”€logsâ”€â”€â”€â†’â”‚ Promtail â”‚â”€â”€â”€â”€â”€â†’â”‚  Loki   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  App    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
                                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Databaseâ”‚â”€â”€â”€metricsâ”€â†’â”‚  Node    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚Alertmana â”‚
â”‚  Redis  â”‚           â”‚ Exporter â”‚                        â”‚  ger     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                â”‚
                                                                â”œâ†’Slack
                                                                â””â†’Email
\`\`\`

### 2.2 ç›‘æ§ç»´åº¦

1. **åŸºç¡€è®¾æ–½ç›‘æ§**: CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ
2. **æœåŠ¡ç›‘æ§**: QPSã€å»¶è¿Ÿã€é”™è¯¯ç‡ã€å¯ç”¨æ€§
3. **ä¸šåŠ¡ç›‘æ§**: ä¼šè®®åˆ›å»ºé‡ã€åœ¨çº¿ç”¨æˆ·ã€å¹¶å‘è¿æ¥
4. **WebRTC ç›‘æ§**: ä¸¢åŒ…ç‡ã€æŠ–åŠ¨ã€ç ç‡ã€å»¶è¿Ÿ

## ä¸‰ã€Prometheus é…ç½®

### 3.1 Prometheus é…ç½®æ–‡ä»¶

\`\`\`yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'ai-meeting-prod'
    env: 'production'

# å‘Šè­¦è§„åˆ™æ–‡ä»¶
rule_files:
  - 'alerts/*.yml'

# Alertmanager é…ç½®
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

# é‡‡é›†ç›®æ ‡
scrape_configs:
  # Node Exporter (ç³»ç»ŸæŒ‡æ ‡)
  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']

  # API æœåŠ¡
  - job_name: 'api'
    static_configs:
      - targets: ['api:3000']
    metrics_path: '/metrics'

  # PostgreSQL
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Caddy/Nginx
  - job_name: 'caddy'
    static_configs:
      - targets: ['caddy:2019']
\`\`\`

### 3.2 åº”ç”¨æŒ‡æ ‡æš´éœ²

åœ¨ NestJS åº”ç”¨ä¸­é›†æˆ Prometheus:

\`\`\`typescript
// src/metrics/metrics.module.ts
import { Module } from '@nestjs/common';
import { PrometheusModule } from '@willsoto/nestjs-prometheus';

@Module({
  imports: [
    PrometheusModule.register({
      defaultMetrics: {
        enabled: true,
      },
      path: '/metrics',
    }),
  ],
})
export class MetricsModule {}
\`\`\`

è‡ªå®šä¹‰ä¸šåŠ¡æŒ‡æ ‡:

\`\`\`typescript
// src/metrics/meeting.metrics.ts
import { Injectable } from '@nestjs/common';
import { Counter, Histogram, Gauge } from 'prom-client';
import { InjectMetric } from '@willsoto/nestjs-prometheus';

@Injectable()
export class MeetingMetrics {
  constructor(
    @InjectMetric('meetings_total')
    public meetingsTotal: Counter<string>,

    @InjectMetric('meetings_active')
    public meetingsActive: Gauge<string>,

    @InjectMetric('meeting_duration_seconds')
    public meetingDuration: Histogram<string>,

    @InjectMetric('participants_total')
    public participantsTotal: Counter<string>,
  ) {}

  recordMeetingCreated(hostId: string) {
    this.meetingsTotal.inc({ host_id: hostId });
    this.meetingsActive.inc();
  }

  recordMeetingEnded(duration: number) {
    this.meetingsActive.dec();
    this.meetingDuration.observe(duration);
  }

  recordParticipantJoined() {
    this.participantsTotal.inc({ action: 'join' });
  }
}
\`\`\`

## å››ã€Grafana ä»ªè¡¨æ¿

### 4.1 ç³»ç»Ÿæ¦‚è§ˆä»ªè¡¨æ¿

**é¢æ¿å†…å®¹**:
1. æœåŠ¡çŠ¶æ€ (UP/DOWN)
2. QPS (Queries Per Second)
3. å“åº”æ—¶é—´ (P50/P95/P99)
4. é”™è¯¯ç‡
5. CPU/å†…å­˜ä½¿ç”¨ç‡
6. ç£ç›˜ I/O

**PromQL æŸ¥è¯¢ç¤ºä¾‹**:

\`\`\`promql
# QPS
rate(http_requests_total[5m])

# P95 å“åº”æ—¶é—´
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# é”™è¯¯ç‡
rate(http_requests_total{status=~"5.."}[5m])
  /
rate(http_requests_total[5m])

# CPU ä½¿ç”¨ç‡
100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# å†…å­˜ä½¿ç”¨ç‡
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes)
  /
node_memory_MemTotal_bytes * 100
\`\`\`

### 4.2 ä¼šè®®ä¸šåŠ¡ä»ªè¡¨æ¿

**é¢æ¿å†…å®¹**:
1. å½“å‰åœ¨çº¿ä¼šè®®æ•°
2. å½“å‰åœ¨çº¿ç”¨æˆ·æ•°
3. ä¼šè®®åˆ›å»ºé€Ÿç‡
4. å¹³å‡ä¼šè®®æ—¶é•¿
5. WebRTC è¿æ¥æˆåŠŸç‡
6. éŸ³è§†é¢‘è´¨é‡æŒ‡æ ‡

**PromQL æŸ¥è¯¢ç¤ºä¾‹**:

\`\`\`promql
# å½“å‰æ´»è·ƒä¼šè®®
meetings_active

# ä¼šè®®åˆ›å»ºé€Ÿç‡ (æ¯åˆ†é’Ÿ)
rate(meetings_total[1m]) * 60

# å¹³å‡ä¼šè®®æ—¶é•¿
rate(meeting_duration_seconds_sum[5m])
  /
rate(meeting_duration_seconds_count[5m])

# WebRTC è¿æ¥æˆåŠŸç‡
webrtc_connections_established
  /
webrtc_connections_attempted * 100
\`\`\`

### 4.3 WebRTC è´¨é‡ä»ªè¡¨æ¿

**é¢æ¿å†…å®¹**:
1. å¹³å‡ä¸¢åŒ…ç‡
2. å¹³å‡æŠ–åŠ¨
3. éŸ³é¢‘ç ç‡
4. è§†é¢‘ç ç‡
5. RTT (Round Trip Time)

## äº”ã€å‘Šè­¦è§„åˆ™

### 5.1 å‘Šè­¦è§„åˆ™æ–‡ä»¶

\`\`\`yaml
# alerts/service.yml
groups:
  - name: service_alerts
    interval: 30s
    rules:
      # æœåŠ¡ä¸å¯ç”¨
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.instance }} has been down for more than 1 minute"

      # é«˜é”™è¯¯ç‡
      - alert: HighErrorRate
        expr: |
          rate(http_requests_total{status=~"5.."}[5m])
            /
          rate(http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate on {{ $labels.job }}"
          description: "Error rate is {{ $value | humanizePercentage }}"

      # å“åº”æ—¶é—´è¿‡é•¿
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95,
            rate(http_request_duration_seconds_bucket[5m])
          ) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time on {{ $labels.job }}"
          description: "P95 response time is {{ $value }}s"

      # CPU ä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance)
            (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100
          ) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}%"

      # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighMemoryUsage
        expr: |
          (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes)
            /
          node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value }}%"

      # ç£ç›˜ç©ºé—´ä¸è¶³
      - alert: LowDiskSpace
        expr: |
          (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.lxcfs"}
            /
          node_filesystem_size_bytes) * 100 < 15
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Available disk space is {{ $value }}%"

  - name: business_alerts
    interval: 30s
    rules:
      # ä¼šè®®åˆ›å»ºå¼‚å¸¸
      - alert: AbnormalMeetingCreationRate
        expr: |
          abs(rate(meetings_total[5m]) - rate(meetings_total[5m] offset 1h))
            /
          rate(meetings_total[5m] offset 1h) > 0.5
        for: 10m
        labels:
          severity: info
        annotations:
          summary: "Abnormal meeting creation rate"
          description: "Meeting creation rate changed by {{ $value | humanizePercentage }}"

      # WebRTC è¿æ¥æˆåŠŸç‡è¿‡ä½
      - alert: LowWebRTCConnectionRate
        expr: |
          webrtc_connections_established
            /
          webrtc_connections_attempted < 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low WebRTC connection success rate"
          description: "Success rate is {{ $value | humanizePercentage }}"
\`\`\`

### 5.2 Alertmanager é…ç½®

\`\`\`yaml
# alertmanager.yml
global:
  resolve_timeout: 5m
  slack_api_url: 'YOUR_SLACK_WEBHOOK_URL'

# å‘Šè­¦è·¯ç”±
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'slack'

  routes:
    # Critical å‘Šè­¦ç«‹å³é€šçŸ¥
    - match:
        severity: critical
      receiver: 'slack-critical'
      continue: true

    # å·¥ä½œæ—¶é—´çš„ Warning å‘Šè­¦
    - match:
        severity: warning
      receiver: 'slack'
      active_time_intervals:
        - work_hours

# æ¥æ”¶å™¨é…ç½®
receivers:
  - name: 'slack'
    slack_configs:
      - channel: '#ai-meeting-alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

  - name: 'slack-critical'
    slack_configs:
      - channel: '#ai-meeting-critical'
        title: 'ğŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'

# æŠ‘åˆ¶è§„åˆ™
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

# æ—¶é—´çª—å£
time_intervals:
  - name: work_hours
    time_intervals:
      - times:
          - start_time: '09:00'
            end_time: '18:00'
        weekdays: ['monday:friday']
\`\`\`

## å…­ã€æ—¥å¿—ç›‘æ§

### 6.1 Loki é…ç½®

\`\`\`yaml
# loki-config.yml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 15m
  chunk_retain_period: 30s

schema_config:
  configs:
    - from: 2024-01-01
      store: boltdb
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 168h

storage_config:
  boltdb:
    directory: /loki/index
  filesystem:
    directory: /loki/chunks

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: true
  retention_period: 168h
\`\`\`

### 6.2 Promtail é…ç½®

\`\`\`yaml
# promtail-config.yml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Docker å®¹å™¨æ—¥å¿—
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*)'
        target_label: 'container'
      - source_labels: ['__meta_docker_container_log_stream']
        target_label: 'stream'

  # åº”ç”¨æ—¥å¿—æ–‡ä»¶
  - job_name: app_logs
    static_configs:
      - targets:
          - localhost
        labels:
          job: app
          __path__: /var/log/ai-meeting/*.log
    pipeline_stages:
      - json:
          expressions:
            level: level
            timestamp: timestamp
            message: message
      - labels:
          level:
      - timestamp:
          source: timestamp
          format: RFC3339
\`\`\`

### 6.3 ç»“æ„åŒ–æ—¥å¿—

åœ¨åº”ç”¨ä¸­ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—:

\`\`\`typescript
// src/logger/logger.service.ts
import { Injectable, LoggerService } from '@nestjs/common';
import * as winston from 'winston';

@Injectable()
export class CustomLogger implements LoggerService {
  private logger: winston.Logger;

  constructor() {
    this.logger = winston.createLogger({
      level: 'info',
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.json()
      ),
      transports: [
        new winston.transports.File({ filename: 'error.log', level: 'error' }),
        new winston.transports.File({ filename: 'combined.log' }),
        new winston.transports.Console({
          format: winston.format.simple(),
        }),
      ],
    });
  }

  log(message: string, context?: string) {
    this.logger.info(message, { context });
  }

  error(message: string, trace?: string, context?: string) {
    this.logger.error(message, { trace, context });
  }

  warn(message: string, context?: string) {
    this.logger.warn(message, { context });
  }
}
\`\`\`

## ä¸ƒã€éƒ¨ç½²é…ç½®

### 7.1 Docker Compose

\`\`\`yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alerts:/etc/prometheus/alerts
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    ports:
      - "3002:3000"
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    restart: unless-stopped

  loki:
    image: grafana/loki:latest
    volumes:
      - ./loki-config.yml:/etc/loki/local-config.yaml
      - loki_data:/loki
    ports:
      - "3100:3100"
    restart: unless-stopped

  promtail:
    image: grafana/promtail:latest
    volumes:
      - ./promtail-config.yml:/etc/promtail/config.yml
      - /var/log:/var/log
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/config.yml
    restart: unless-stopped

  node-exporter:
    image: prom/node-exporter:latest
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:
  loki_data:
\`\`\`

## å…«ã€ç›‘æ§æœ€ä½³å®è·µ

### 8.1 æŒ‡æ ‡å‘½åè§„èŒƒ

- ä½¿ç”¨å°å†™å­—æ¯å’Œä¸‹åˆ’çº¿
- åŒ…å«å•ä½åç¼€ (\_seconds, \_bytes, \_total)
- ä½¿ç”¨æœ‰æ„ä¹‰çš„æ ‡ç­¾

### 8.2 å‘Šè­¦è®¾è®¡åŸåˆ™

- **å¯æ“ä½œ**: æ¯ä¸ªå‘Šè­¦éƒ½åº”è¯¥æœ‰æ˜ç¡®çš„å¤„ç†æ­¥éª¤
- **å»å™ª**: é¿å…å‘Šè­¦é£æš´,åˆç†è®¾ç½®é˜ˆå€¼
- **åˆ†çº§**: Critical > Warning > Info
- **æ—¶é—´çª—å£**: è®¾ç½®åˆç†çš„ `for` æŒç»­æ—¶é—´

### 8.3 ä»ªè¡¨æ¿è®¾è®¡

- **åˆ†å±‚**: ç³»ç»Ÿ â†’ æœåŠ¡ â†’ ä¸šåŠ¡
- **å…³é”®æŒ‡æ ‡ä¼˜å…ˆ**: RED (Rate, Errors, Duration) / USE (Utilization, Saturation, Errors)
- **å¯è¯»æ€§**: åˆç†ä½¿ç”¨å›¾è¡¨ç±»å‹

## ä¹ã€æ•…éšœæ’æŸ¥

### 9.1 å¸¸è§é—®é¢˜

**Prometheus æ•°æ®ä¸¢å¤±**:
- æ£€æŸ¥å­˜å‚¨ç©ºé—´
- æ£€æŸ¥é‡‡é›†ç›®æ ‡å¯è¾¾æ€§
- éªŒè¯ scrape_interval é…ç½®

**Grafana æ— æ•°æ®**:
- æ£€æŸ¥æ•°æ®æºé…ç½®
- éªŒè¯ PromQL æŸ¥è¯¢
- æ£€æŸ¥æ—¶é—´èŒƒå›´é€‰æ‹©

**å‘Šè­¦æœªè§¦å‘**:
- æ£€æŸ¥å‘Šè­¦è§„åˆ™è¯­æ³•
- éªŒè¯ Alertmanager é…ç½®
- æ£€æŸ¥è·¯ç”±è§„åˆ™

## åã€ç›¸å…³æ–‡æ¡£

- [CI/CD æ–‡æ¡£](./cicd.md)
- [éƒ¨ç½²æ–‡æ¡£](./deployment.md)
- [æ€§èƒ½ä¼˜åŒ–](./performance.md)
